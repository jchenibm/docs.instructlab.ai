# 技能指南

## 什么是"技能"？

你可以向分类系统贡献各种类型的技能。

### 组合技能

技能是表现性的。当你为模型创建技能时，你是在教它如何做某事："给我写一首歌"、"重新排列句子中的单词"或"总结一封电子邮件"。

组合技能有两种类型：

#### 自由形式组合技能

自由形式组合技能是表现性的，并且**不**需要额外的上下文。自由形式技能的一个例子是教模型押韵的单词。你可以提供"与 'tool' 押韵的单词"的例子。通过提供这些例子，你实际上是在激活 LLM 的潜在知识。在我们的例子中，你是在使 LLM 能够在其潜在知识中识别押韵的单词。

自由形式技能包括：

* 说话像尤达大师
* 转换为驼峰命名法
* 给我写一首打油诗
* 生成 StabeDiffusion 提示

#### 有基础的组合技能

有基础的技能是表现性的，并且**确实**需要额外的上下文。有基础技能的一个例子是读取表格布局中的单元格值，或解析 JSON 文件。要创建一个读取 markdown 格式表格布局的有基础技能，额外的上下文可以是一个示例表格布局。这个额外的上下文包含在技能的 YAML 中，而不是外部的。

!!! note
    表格布局的内容不会用于训练或对齐模型；只会使用表格布局格式本身。

有基础的技能包括：

* 创建游戏，如数独或井字棋
* 总结或提取文本片段
* 在会议记录中找到未解决的项目

[有基础组合技能拉取请求示例](https://github.com/instructlab/taxonomy/pull/250)

### 核心技能

核心技能是基础技能，如数学、推理和编码。

!!! note
    与**知识**和**组合技能**不同，核心技能不能贡献到分类树中。因此，从这一点开始，当你看到引用向分类系统贡献"技能"时，指的是**组合技能**。

## 接受的技能

### 创意写作/诗学

欢迎向 LLM 添加新类型的文档和写作风格。考虑：

* 歌词
* 独白
* 五段式论文
* 论证

### 学习格式化信息

有助于更好地格式化和重新组装信息的技能。

### 表格分析和处理

考虑：

* 对表格内容进行口头推理和得出结论
* 排序
* 选择
* 连接

### 定性推理和思维链推理

示例：

> Mary 比 John 高。
> John 比 Anna 高。
> Anna 比 Mary 高吗？

示例：

> 一头大象、一只老鼠和一匹马在一个房间里。如果他们按大小顺序站立，顺序会是怎样的？

这类技能中的优秀示例应该包含正确的推理过程，而不仅仅是答案是什么。

### 应用题

你的 LLM 比二年级学生聪明吗？

### 信任和安全

请在你的示例中避免 HAP（仇恨、滥用和亵渎）和 PII（个人身份信息）。

任何与信任和安全相关的内容都将被标记为需要更高级别的审查。

### 搜索、提取和总结

欢迎从"上下文"字段中提供的信息中选择奇特的信息、得出结论、提取信息、得出见解或生成待办事项的技能。

### 复杂规则集和游戏

!!! note
    这是需要*有基础技能*的一个很好的例子。有基础的技能需要用户提供上下文，其中包含模型在处理过程中需要考虑的信息。这与*知识*不同，在知识中，模型需要从调优过程中获取事实和背景知识。
    在调优有基础技能时添加的上下文需要在推理时由最终用户再次提供。这里的技能是更好地遵守规则集。

要为结构化游戏或其他具有复杂规则集的任务添加技能，请使用有基础的技能。在每个示例中将游戏规则添加为"上下文"。将解释添加为问题。

### 写作风格和个性

在添加技能时，要期望你是在调优一个相当通用的 LLM，使其在特定情况下表现得更好。

如果你想添加一个技能来更好地采用特定的个性 - 比如说，"19 世纪的一个小男孩" - 这个上下文需要在"上下文"或"问题"字段中提供。

### 遵循指令的行为

LLM 可以更好地遵循提示中关于如何完成任务的额外指令，例如："将你的回答限制在 200 字以内。"或："只生成 10 个项目。"改进这种行为的技能将帮助模型表现得更精确。

## 要避免的技能

有几种类型的技能，我们不期望这个程序能改进。这些类别中的大多数技能都会被拒绝。

### 数学

试图让 LLM 解决数学问题的尝试将被拒绝。

### 基于现实世界知识的技能

除非可以将其构建为"有基础的技能"，即用户需要提供上下文，否则知识贡献将是分类系统的一个单独部分。技能不应期望模型自己提出事实，而是组装提供的事实。

### 红队测试

目前将拒绝对抗性的问题和答案。

### 图灵完备式问题

这些是一个边缘情况，但像回文和正则表达式这样的东西，用非随机程序很容易得到正确答案，目前不是好的目标。

在提交 PR 之前，如果你在这个领域有想法，请在分类系统仓库中开一个 issue。

### 对原始响应的小改动

如果原始 LLM 响应已经很接近，但它没有完全符合你的确切期望，技能不是解决这个问题的正确方法。

## 避免这些主题

虽然调优过程最终可能会从帮助模型处理复杂的社会主题中受益，但目前这是一个我们不想轻易处理的活跃研究领域。因此，请避免在你的提交中包含以下主题：

* PII（个人身份信息）或任何侵犯个人隐私权的内容
* 暴力，包括自残
* 网络欺凌
* 内部文档或其他对你的雇主或组织保密的信息，如商业机密
* 歧视
* 宗教
  * 诸如"[根据 2011 年人口普查，基督教是尼泊尔第五大宗教，有 375,699 名信徒，占人口的 1.4%](https://en.wikipedia.org/wiki/Christianity_in_Nepal)"这样的事实作为知识贡献是可以的。但是，支持或反对任何宗教信仰都是不可接受的。
* 医疗或健康信息
  * 诸如"[在哺乳动物中，肺部通气是通过吸气（呼吸）实现的](https://opentextbc.ca/biology/chapter/11-3-circulatory-and-respiratory-systems/)"这样的事实作为知识贡献是可以的。但是，定制的医疗/健康建议是不可接受的。
* 金融信息
  * 诸如"[自由放任经济学...认为市场力量应该单独驱动经济，政府应该避免直接干预或调节经济系统](https://openstax.org/books/world-history-volume-2/pages/6-3-capitalism-and-the-first-industrial-revolution)"这样的事实作为知识贡献是可以的。但是，定制的金融建议是不可接受的。
* 法律和解/缓解措施
* 性别偏见
* 敌对语言、威胁、诽谤以及贬低或不敏感的笑话或评论
* 亵渎
* 色情和性暗示或性挑逗内容
* 任何允许进行影响个人权利或福祉的自动化决策的贡献，如社会评分
* 任何参与政治竞选或游说的贡献

我们也不接受以下内容的提交：

* 笑话
* 诗歌
* 代码
  * 任何可以追溯到计算机代码的代码相关内容。不限于 `sed` 或 `bash` 或用于 OpenShift 或 Kubernetes 的 `yaml`，到 `python` 片段到 `Java` 建议。有专门针对这个领域的模型，目前这个模型不接受这类内容。
* "AI 护栏"
  * 我们期望我们的上游工程团队创建这些类型的技能和安全保护。我们感谢我们的社区想要帮助这一点，但有一些基础的工程决策，从社区接受这些可能会与这些决策冲突。

我们在项目开始时收到了许多笑话和诗歌提交，由于笑话和诗歌是"仁者见仁"的，而双关语对英语母语者来说需要细微的理解，我们意识到我们可能在无意中给我们的模型带来了偏见。我们发现处理这两个主题都有其自身的挑战，如果我们想要一些通用的东西，找到共识是不成功的。

## 建立你的 LLM 直觉

LLM 有其固有的限制，使得某些任务极其困难，比如做数学题。它们在其他任务上表现出色，比如创意写作。而在逻辑推理等方面还可以做得更好。

在生成技能时要考虑这些。欢迎第一和第二类的技能。第三类的技能通常是边缘性的，可能会被拒绝。

### LLM 擅长的领域

欢迎这类技能，因为改进这些能力有助于我们在 LLM 可以擅长的任务类型上做得更好。

然而，对于这些方面，LLM 通常已经有出色的表现。在构建你的提交之前，请在 `lab chat` 中尝试 3-5 个示例来确认模型的不足，然后在你的拉取请求 (PR) 中分享这些示例。

* 头脑风暴
* 创造力
* 连接信息
* 跨语言行为

### LLM 需要帮助的领域

欢迎这类技能，因为 LLM 在这些类型的主题中的行为对模型来说很难正确处理。尝试几个示例来理解模型在执行这些类型任务时的能力的细微差别，然后考虑在你的调优过程中使用对结果的纠正。

* 推理链
* 分析
* 故事情节
* 重组信息
* 有效和简洁的总结

### LLM 不太擅长的领域

这类技能是 LLM 挣扎的领域，而且可能一直会挣扎。通过自然语言查询的概率来解决数学和计算问题可能不是最好的方法。也就是说，改进其中一些基础技能可能是这项工作将来要解决的问题，但目前还不是时候。

这些类别中的大多数技能提交可能会被拒绝。

特别是对于幻觉，试图用技能来解决这个问题不太可能成功。考虑在知识分类开放时向其贡献，以改进模型对事实的理解。

* 数学
* 计算
* "图灵完备"类型的任务
* 仅生成真实世界的信息（它们容易产生幻觉）
